import os
import json
import logging
from typing import Annotated
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langgraph.graph import MessagesState
from langgraph.graph.message import add_messages
from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage
from coze_coding_utils.runtime_ctx.context import default_headers, new_context
from storage.memory.memory_saver import get_memory_saver
from tools.pdf_generator import generate_opc_pdf
from tools.simple_payment import SIMPLE_PAYMENT_TOOLS
from tools.wechat_group_info import get_wechat_group_info
from tools.customer_db_tools import (
    save_user_info,
    save_payment_and_pdf,
    mark_user_joined_group,
    get_customer_info,
    save_recommendations
)

logger = logging.getLogger(__name__)

LLM_CONFIG = "config/agent_llm_config.json"

# é»˜è®¤ä¿ç•™æœ€è¿‘ 20 è½®å¯¹è¯ (40 æ¡æ¶ˆæ¯)
MAX_MESSAGES = 40

def _windowed_messages(old, new):
    """æ»‘åŠ¨çª—å£: åªä¿ç•™æœ€è¿‘ MAX_MESSAGES æ¡æ¶ˆæ¯"""
    combined = add_messages(old, new)
    # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨ç±»å‹
    if not isinstance(combined, list):
        return [combined]
    return combined[-MAX_MESSAGES:] if len(combined) > MAX_MESSAGES else combined

class AgentState(MessagesState):
    messages: Annotated[list[AnyMessage], _windowed_messages]

# æ¬¢è¿æ¶ˆæ¯ï¼ˆå½“ç”¨æˆ·æœªä¸»åŠ¨æé—®æ—¶è‡ªåŠ¨å‘é€ï¼‰
WELCOME_MESSAGE = """ä½ å¥½ï¼æˆ‘æ˜¯OPCè¶…çº§ä¸ªä½“å­µåŒ–åŠ©æ‰‹ã€‚æˆ‘ä»¬æ·±åº¦ç ”ç©¶äº†100ä¸ªè¶…çº§ä¸ªä½“æˆåŠŸæ¡ˆä¾‹ï¼Œå¹¶é’ˆå¯¹å…¨å›½ä¸»è¦åŸå¸‚çš„å¸‚åœºç¯å¢ƒè¿›è¡Œäº†å……åˆ†è°ƒç ”ã€‚åŸºäºè¿™äº›æ•°æ®å’Œç»éªŒï¼Œæˆ‘å¯ä»¥ä¸ºä½ æ¨èæœ€é€‚åˆçš„åˆ›ä¸šæ–¹å‘ï¼Œå¹¶æä¾›èµ„æºå¯¹æ¥å­µåŒ–ç¾¤çš„æŒç»­æ”¯æŒã€‚

ä¸ºäº†ç»™ä½ ç²¾å‡†åŒ¹é…åˆ›ä¸šé¡¹ç›®ï¼Œè¯·å‘Šè¯‰æˆ‘ä»¥ä¸‹ä¿¡æ¯ï¼š

1. ä½ çš„å¸¸ä½åœ°å€æˆ–è®¡åˆ’åˆ›ä¸šçš„åŸå¸‚æ˜¯å“ªé‡Œï¼Ÿ
2. ä½ æ‹¥æœ‰å“ªäº›ä¸“ä¸šæŠ€èƒ½ï¼Ÿæ¯”å¦‚ç¼–ç¨‹ã€è®¾è®¡ã€å†™ä½œã€è¥é”€ã€æ‘„å½±ç­‰ï¼Ÿ
3. èƒ½ç®€å•ä»‹ç»ä¸€ä¸‹ä½ çš„å·¥ä½œç»éªŒå—ï¼ŸåŒ…æ‹¬æ‰€åœ¨è¡Œä¸šã€èŒä½å’Œå·¥ä½œå¹´é™ï¼Ÿ
4. ä½ çš„ä¸ªäººå…´è¶£å’Œçˆ±å¥½æ˜¯ä»€ä¹ˆï¼Ÿæ¯”å¦‚æ˜¯å¦å–œæ¬¢å†…å®¹åˆ›ä½œã€æ‰‹å·¥åˆ¶ä½œã€ç¤¾äº¤æ´»åŠ¨ç­‰ï¼Ÿ

ğŸ’¡ ä½ ä¹Ÿå¯ä»¥ç›´æ¥å‘Šè¯‰æˆ‘ä½ æƒ³äº†è§£çš„å†…å®¹ï¼Œæ¯”å¦‚ï¼š
- "æˆ‘æƒ³åšXXç±»å‹çš„åˆ›ä¸š"
- "å¸®æˆ‘æ¨èé€‚åˆæˆ‘çš„åˆ›ä¸šé¡¹ç›®"
- "æˆ‘æƒ³äº†è§£AIå·¥å…·æ¨è"

æœŸå¾…ä½ çš„å›å¤ï¼"""

def get_welcome_message() -> str:
    """è·å–æ¬¢è¿æ¶ˆæ¯ï¼Œå¯ä»¥ä»é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡è¯»å–"""
    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–
    welcome_msg = os.getenv("AGENT_WELCOME_MESSAGE", "")
    if welcome_msg:
        return welcome_msg
    # å¦åˆ™ä½¿ç”¨é»˜è®¤æ¬¢è¿è¯­
    return WELCOME_MESSAGE

def build_agent(ctx=None):
    workspace_path = os.getenv("COZE_WORKSPACE_PATH", "/workspace/projects")
    config_path = os.path.join(workspace_path, LLM_CONFIG)

    with open(config_path, 'r', encoding='utf-8') as f:
        cfg = json.load(f)

    api_key = os.getenv("COZE_WORKLOAD_IDENTITY_API_KEY")
    base_url = os.getenv("COZE_INTEGRATION_MODEL_BASE_URL")

    llm = ChatOpenAI(
        model=cfg['config'].get("model"),
        api_key=api_key,
        base_url=base_url,
        temperature=cfg['config'].get('temperature', 0.7),
        streaming=True,
        timeout=cfg['config'].get('timeout', 600),
        extra_body={
            "thinking": {
                "type": cfg['config'].get('thinking', 'disabled')
            }
        },
        default_headers=default_headers(ctx) if ctx else {}
    )

    # å¯¼å…¥æ‰€æœ‰å·¥å…·
    tools = [
        generate_opc_pdf,
        *SIMPLE_PAYMENT_TOOLS,  # æ·»åŠ æ”¶æ¬¾å·¥å…·ï¼ˆget_payment_qrcode, confirm_paymentï¼‰
        get_wechat_group_info,
        # æ•°æ®åº“å·¥å…·
        save_user_info,
        save_payment_and_pdf,
        mark_user_joined_group,
        get_customer_info,
        save_recommendations
    ]

    return create_agent(
        model=llm,
        system_prompt=cfg.get("sp"),
        tools=tools,
        checkpointer=get_memory_saver(),
        state_schema=AgentState,
    )
